{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Spacy comes with a variety of different models that can used per language. For instance, the models for English are available [here](https://spacy.io/models/en). You'll need to download each model separately:\n",
    "\n",
    "```python\n",
    "python3 -m spacy download en_core_web_sm\n",
    "python3 -m spacy download en_core_web_md\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from en-core-web-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: click<8.1.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: setuptools in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.7 MB 28.0 MB/s eta 0:00:01     |██████████████████████████████▉ | 44.1 MB 28.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from en-core-web-md==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.62.1)\n",
      "Requirement already satisfied: click<8.1.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.1)\n",
      "Requirement already satisfied: jinja2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: setuptools in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/akshaybhide/opt/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "##download english core web corpus, small and medium\n",
    "##the larger the model, the better the performnace (sm is 12 mb compressed, medium is around 90 compressed)\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pattern Matching Using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The below code and example is from Ashiq KS's article [Rule-Based Matching with spacy](https://medium.com/@ashiqgiga07/rule-based-matching-with-spacy-295b76ca2b68):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#The input text string is converted to a Document object\n",
    "text = '''\n",
    "Computer programming is the process of writing instructions that get executed by computers. \n",
    "The instructions, also known as code, are written in a programming language which the computer \n",
    "can understand and use to perform a task or solve a problem. Basic computer programming involves \n",
    "the analysis of a problem and development of a logical sequence of instructions to solve it. \n",
    "There can be numerous paths to a solution and the computer programmer seeks to design and \n",
    "code that which is most efficient. Among the programmer’s tasks are understanding requirements, \n",
    "determining the right programming language to use, designing or architecting the solution, coding, \n",
    "testing, debugging and writing documentation so that the solution can be easily\n",
    "understood by other programmers.Computer programming is at the heart of computer science. It is the \n",
    "implementation portion of software development, application development \n",
    "and software engineering efforts, transforming ideas and theories into actual, working solutions.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher #import Matcher class from spacy\n",
    "#import the Span class to extract the words from the document object\n",
    "from spacy.tokens import Span \n",
    "\n",
    "#Language class with the English model 'en_core_web_sm' is loaded\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text) # convert the string above to a document\n",
    "\n",
    "#instantiate a new Matcher class object \n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Define the Target Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `pattern` object that you define should be a list of dictionary elements, each dictionary describing the token to match for. \n",
    "\n",
    "Here, we are matching for the usage of `computer` as a `NOUN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#define the pattern\n",
    "pattern = [{'LOWER': 'computer', 'POS': 'NOUN'},\n",
    "             {'POS':{'NOT_IN': ['VERB']}}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the Pattern into the Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#add the pattern to the previously created matcher object\n",
    "matcher.add(\"Matching\", None, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regular Expressions in Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below example can be found at https://spacy.io/usage/rule-based-matching. It uses the `re.finditer()` function to\n",
    "quickly iterate through all the matches found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match: United States\n",
      "Found match: United States\n",
      "Found match: US\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "##think of this as 1 row of your dataframe, 1 document\n",
    "doc = nlp(\"The United States of America (USA) are commonly known as the United States (U.S. or US) or America.\")\n",
    "\n",
    "##simple regex cleaning\n",
    "expression = r\"\\b[Uu](nited|\\.?) ?[Ss](tates|\\.?)\\b\"\n",
    "##finditer creates an iterator, allows you to \"loop\" through the text to find matches\n",
    "for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    # This is a Span object or None if match doesn't map to valid token sequence\n",
    "    if span is not None:\n",
    "        print(\"Found match:\", span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm\n",
    "# !python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>tag</th>\n",
       "      <th>dependency</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alphanumeric</th>\n",
       "      <th>is_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steve</td>\n",
       "      <td>Steve</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>conj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>aux</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma part_of_speech  tag dependency  shape  is_alphanumeric  \\\n",
       "0  Steve  Steve          PROPN  NNP   compound  Xxxxx             True   \n",
       "1   Jobs   Jobs          PROPN  NNP      nsubj   Xxxx             True   \n",
       "2    and    and          CCONJ   CC         cc    xxx             True   \n",
       "3  Apple  Apple          PROPN  NNP       conj  Xxxxx             True   \n",
       "4     is     be            AUX  VBZ        aux     xx             True   \n",
       "\n",
       "   is_stopword  \n",
       "0        False  \n",
       "1        False  \n",
       "2         True  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rows = []\n",
    "doc = nlp(u\"Steve Jobs and Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    rows.append((token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop))\n",
    "    \n",
    "data = pd.DataFrame(rows, columns=[\"text\", \"lemma\", \"part_of_speech\", \"tag\", \"dependency\", \"shape\", \"is_alphanumeric\", \"is_stopword\"])\n",
    "data.head()\n",
    "\n",
    "##tokenization done\n",
    "##lemmatization done\n",
    "##part of speech tagged\n",
    "##dependency also found - compound phrase, nsubj is name of the subject\n",
    "##finds stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs 0 10 PERSON\n",
      "Apple 15 20 ORG\n",
      "U.K. 42 46 GPE\n",
      "$1 billion 59 69 MONEY\n"
     ]
    }
   ],
   "source": [
    "# example from spacy docs\n",
    "doc = nlp(u\"Steve Jobs and Apple is looking at buying U.K. startup for $1 billion\")\n",
    "import en_core_web_sm\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "    \n",
    "##named entities - people, places, things, concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize this using displacy:\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings (word2vec Introduction) from Intro to Algorithmic Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL IMAGES COMING FROM TEXTBOOK - introduction to algorithmic marketing by ilya katsov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag of Words (Use Context to Predict Target Word)\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/word2vec_cbow.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/softmax.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/skipgram.png \"Logo Title Text 1\")\n",
    "\n",
    "## Softmax\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/wordembedding_cluster.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import en_core_web_md\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dog - cat: 0.6064711809158325\n",
      " dog - Beijing: 0.26680809259414673\n",
      " dog - sad: 0.23861631751060486\n",
      " dog - depressed: 0.15567244589328766\n",
      " dog - couch: 0.40754207968711853\n",
      " dog - sofa: 0.28589534759521484\n",
      " dog - canine: 0.40234488248825073\n",
      " dog - China: 0.3280990421772003\n",
      " dog - Chinese: 0.223441019654274\n",
      " dog - France: 0.45519712567329407\n",
      " dog - Paris: 0.4896498918533325\n",
      " dog - banana: 0.37603437900543213\n",
      " cat - dog: 0.6064711809158325\n",
      " cat - Beijing: 0.34632179141044617\n",
      " cat - sad: 0.2476261705160141\n",
      " cat - depressed: 0.08602733165025711\n",
      " cat - couch: 0.2503412663936615\n",
      " cat - sofa: 0.25963470339775085\n",
      " cat - canine: 0.38918542861938477\n",
      " cat - China: 0.28076714277267456\n",
      " cat - Chinese: 0.11958666890859604\n",
      " cat - France: 0.3794781565666199\n",
      " cat - Paris: 0.39501628279685974\n",
      " cat - banana: 0.4623035490512848\n",
      " Beijing - dog: 0.26680809259414673\n",
      " Beijing - cat: 0.34632179141044617\n",
      " Beijing - sad: 0.2716704308986664\n",
      " Beijing - depressed: 0.22452880442142487\n",
      " Beijing - couch: 0.13369260728359222\n",
      " Beijing - sofa: 0.14226152002811432\n",
      " Beijing - canine: 0.0972571149468422\n",
      " Beijing - China: 0.5439580082893372\n",
      " Beijing - Chinese: 0.2218572497367859\n",
      " Beijing - France: 0.42475029826164246\n",
      " Beijing - Paris: 0.6329951286315918\n",
      " Beijing - banana: 0.19911344349384308\n",
      " sad - dog: 0.23861631751060486\n",
      " sad - cat: 0.2476261705160141\n",
      " sad - Beijing: 0.2716704308986664\n",
      " sad - depressed: 0.3655848801136017\n",
      " sad - couch: 0.07161746174097061\n",
      " sad - sofa: 0.06528615206480026\n",
      " sad - canine: 0.11390763521194458\n",
      " sad - China: 0.06946887820959091\n",
      " sad - Chinese: 0.2303980588912964\n",
      " sad - France: 0.16152942180633545\n",
      " sad - Paris: 0.14384041726589203\n",
      " sad - banana: 0.26627346873283386\n",
      " depressed - dog: 0.15567244589328766\n",
      " depressed - cat: 0.08602733165025711\n",
      " depressed - Beijing: 0.22452880442142487\n",
      " depressed - sad: 0.3655848801136017\n",
      " depressed - couch: 0.15045148134231567\n",
      " depressed - sofa: -0.03099963068962097\n",
      " depressed - canine: 0.19041414558887482\n",
      " depressed - China: 0.18923704326152802\n",
      " depressed - Chinese: 0.1768854856491089\n",
      " depressed - France: 0.1509069800376892\n",
      " depressed - Paris: 0.09740877896547318\n",
      " depressed - banana: -0.06587128341197968\n",
      " couch - dog: 0.40754207968711853\n",
      " couch - cat: 0.2503412663936615\n",
      " couch - Beijing: 0.13369260728359222\n",
      " couch - sad: 0.07161746174097061\n",
      " couch - depressed: 0.15045148134231567\n",
      " couch - sofa: 0.307026743888855\n",
      " couch - canine: 0.11578931659460068\n",
      " couch - China: 0.29890719056129456\n",
      " couch - Chinese: 0.3300574719905853\n",
      " couch - France: 0.29997438192367554\n",
      " couch - Paris: 0.15055692195892334\n",
      " couch - banana: 0.020790820941329002\n",
      " sofa - dog: 0.28589534759521484\n",
      " sofa - cat: 0.25963470339775085\n",
      " sofa - Beijing: 0.14226152002811432\n",
      " sofa - sad: 0.06528615206480026\n",
      " sofa - depressed: -0.03099963068962097\n",
      " sofa - couch: 0.307026743888855\n",
      " sofa - canine: 0.2369140386581421\n",
      " sofa - China: 0.05206387862563133\n",
      " sofa - Chinese: 0.1550963968038559\n",
      " sofa - France: 0.14373740553855896\n",
      " sofa - Paris: 0.370871901512146\n",
      " sofa - banana: 0.3729729950428009\n",
      " canine - dog: 0.40234488248825073\n",
      " canine - cat: 0.38918542861938477\n",
      " canine - Beijing: 0.0972571149468422\n",
      " canine - sad: 0.11390763521194458\n",
      " canine - depressed: 0.19041414558887482\n",
      " canine - couch: 0.11578931659460068\n",
      " canine - sofa: 0.2369140386581421\n",
      " canine - China: 0.03372814878821373\n",
      " canine - Chinese: -0.016037508845329285\n",
      " canine - France: 0.10409574210643768\n",
      " canine - Paris: 0.21894283592700958\n",
      " canine - banana: 0.22045570611953735\n",
      " China - dog: 0.3280990421772003\n",
      " China - cat: 0.28076714277267456\n",
      " China - Beijing: 0.5439580082893372\n",
      " China - sad: 0.06946887820959091\n",
      " China - depressed: 0.18923704326152802\n",
      " China - couch: 0.29890719056129456\n",
      " China - sofa: 0.05206387862563133\n",
      " China - canine: 0.03372814878821373\n",
      " China - Chinese: 0.36110448837280273\n",
      " China - France: 0.576897382736206\n",
      " China - Paris: 0.48589521646499634\n",
      " China - banana: 0.11915622651576996\n",
      " Chinese - dog: 0.223441019654274\n",
      " Chinese - cat: 0.11958666890859604\n",
      " Chinese - Beijing: 0.2218572497367859\n",
      " Chinese - sad: 0.2303980588912964\n",
      " Chinese - depressed: 0.1768854856491089\n",
      " Chinese - couch: 0.3300574719905853\n",
      " Chinese - sofa: 0.1550963968038559\n",
      " Chinese - canine: -0.016037508845329285\n",
      " Chinese - China: 0.36110448837280273\n",
      " Chinese - France: 0.4958896338939667\n",
      " Chinese - Paris: 0.32186079025268555\n",
      " Chinese - banana: -0.03121802769601345\n",
      " France - dog: 0.45519712567329407\n",
      " France - cat: 0.3794781565666199\n",
      " France - Beijing: 0.42475029826164246\n",
      " France - sad: 0.16152942180633545\n",
      " France - depressed: 0.1509069800376892\n",
      " France - couch: 0.29997438192367554\n",
      " France - sofa: 0.14373740553855896\n",
      " France - canine: 0.10409574210643768\n",
      " France - China: 0.576897382736206\n",
      " France - Chinese: 0.4958896338939667\n",
      " France - Paris: 0.5458804965019226\n",
      " France - banana: 0.118282750248909\n",
      " Paris - dog: 0.4896498918533325\n",
      " Paris - cat: 0.39501628279685974\n",
      " Paris - Beijing: 0.6329951286315918\n",
      " Paris - sad: 0.14384041726589203\n",
      " Paris - depressed: 0.09740877896547318\n",
      " Paris - couch: 0.15055692195892334\n",
      " Paris - sofa: 0.370871901512146\n",
      " Paris - canine: 0.21894283592700958\n",
      " Paris - China: 0.48589521646499634\n",
      " Paris - Chinese: 0.32186079025268555\n",
      " Paris - France: 0.5458804965019226\n",
      " Paris - banana: 0.36768609285354614\n",
      " banana - dog: 0.37603437900543213\n",
      " banana - cat: 0.4623035490512848\n",
      " banana - Beijing: 0.19911344349384308\n",
      " banana - sad: 0.26627346873283386\n",
      " banana - depressed: -0.06587128341197968\n",
      " banana - couch: 0.020790820941329002\n",
      " banana - sofa: 0.3729729950428009\n",
      " banana - canine: 0.22045570611953735\n",
      " banana - China: 0.11915622651576996\n",
      " banana - Chinese: -0.03121802769601345\n",
      " banana - France: 0.118282750248909\n",
      " banana - Paris: 0.36768609285354614\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'dog cat Beijing sad depressed couch sofa canine China Chinese France Paris banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if token1 != token2:\n",
    "            print(f\" {token1} - {token2}: {1 - cosine(token1.vector, token2.vector)}\")\n",
    "            \n",
    "##china france high similarity (often times they are used in the same context)\n",
    "##paris france high similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "tokens = nlp('dog')\n",
    "\n",
    "print(tokens.vector.shape)\n",
    "nlp = en_core_web_md.load()\n",
    "\n",
    "tokens = nlp('dog')\n",
    "\n",
    "print(tokens.vector.shape)\n",
    "\n",
    "##vector based on the different models based on the different spacy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.0176e-01,  3.7057e-01,  2.1281e-02, -3.4125e-01,  4.9538e-02,\n",
       "        2.9440e-01, -1.7376e-01, -2.7982e-01,  6.7622e-02,  2.1693e+00,\n",
       "       -6.2691e-01,  2.9106e-01, -6.7270e-01,  2.3319e-01, -3.4264e-01,\n",
       "        1.8311e-01,  5.0226e-01,  1.0689e+00,  1.4698e-01, -4.5230e-01,\n",
       "       -4.1827e-01, -1.5967e-01,  2.6748e-01, -4.8867e-01,  3.6462e-01,\n",
       "       -4.3403e-02, -2.4474e-01, -4.1752e-01,  8.9088e-02, -2.5552e-01,\n",
       "       -5.5695e-01,  1.2243e-01, -8.3526e-02,  5.5095e-01,  3.6410e-01,\n",
       "        1.5361e-01,  5.5738e-01, -9.0702e-01, -4.9098e-02,  3.8580e-01,\n",
       "        3.8000e-01,  1.4425e-01, -2.7221e-01, -3.7016e-01, -1.2904e-01,\n",
       "       -1.5085e-01, -3.8076e-01,  4.9583e-02,  1.2755e-01, -8.2788e-02,\n",
       "        1.4339e-01,  3.2537e-01,  2.7226e-01,  4.3632e-01, -3.1769e-01,\n",
       "        7.9405e-01,  2.6529e-01,  1.0135e-01, -3.3279e-01,  4.3117e-01,\n",
       "        1.6687e-01,  1.0729e-01,  8.9418e-02,  2.8635e-01,  4.0117e-01,\n",
       "       -3.9222e-01,  4.5217e-01,  1.3521e-01, -2.8878e-01, -2.2819e-02,\n",
       "       -3.4975e-01, -2.2996e-01,  2.0224e-01, -2.1177e-01,  2.7184e-01,\n",
       "        9.1703e-02, -2.0610e-01, -6.5758e-01,  1.8949e-01, -2.6756e-01,\n",
       "        9.2639e-02,  4.3316e-01, -4.8868e-01, -3.8309e-01, -2.1910e-01,\n",
       "       -4.4183e-01,  9.8044e-01,  6.7423e-01,  8.4003e-01, -1.8169e-01,\n",
       "        1.7385e-01,  4.1848e-01,  1.6098e-01, -1.0490e-01, -4.1965e-01,\n",
       "       -3.5660e-01, -1.6837e-01, -6.3458e-01,  3.8422e-01, -3.5043e-01,\n",
       "        1.7486e-01,  5.3528e-01,  2.0143e-01,  3.7877e-02,  4.7105e-01,\n",
       "       -4.4344e-01,  1.6840e-01, -1.6685e-01, -2.4022e-01, -1.0077e-01,\n",
       "        3.0334e-01,  4.2730e-01,  3.3803e-01, -4.3481e-01,  1.1343e-01,\n",
       "        6.1958e-02,  6.1808e-02, -1.4007e-01,  8.2018e-02, -3.9130e-02,\n",
       "        5.1442e-02,  2.8725e-01,  5.8025e-01, -5.7641e-01, -3.4652e-01,\n",
       "        1.0132e-01,  1.4463e-01,  1.1569e-02, -3.3701e-01, -1.7586e-01,\n",
       "       -3.5724e-01, -2.1423e-01,  1.1429e-02,  4.7645e-01, -3.7463e-02,\n",
       "       -2.9488e-01, -1.7465e-01,  3.0255e-01,  6.0317e-01, -6.6790e-02,\n",
       "       -2.7050e+00, -7.0308e-01,  4.0548e-01,  6.2874e-01,  6.3080e-01,\n",
       "       -5.4513e-01, -9.6191e-03,  2.6533e-01,  2.3391e-01, -5.1886e-02,\n",
       "       -6.5759e-03,  1.8573e-02, -4.5693e-01, -7.0351e-02, -3.0621e-01,\n",
       "       -1.4018e-02, -2.0408e-01,  3.7100e-01, -3.2354e-01, -8.4646e-01,\n",
       "        2.7092e-01, -1.1961e-01, -9.5576e-02, -6.0464e-01,  4.2409e-02,\n",
       "        2.4656e-01,  3.8445e-02, -2.5467e-02, -9.2908e-02, -2.1356e-01,\n",
       "        3.6120e-01,  1.9113e-02,  6.2741e-02, -1.3083e-01, -1.5146e-03,\n",
       "        5.8238e-01, -1.8956e-01,  7.8105e-01,  1.0477e-02,  1.0928e+00,\n",
       "        1.0140e-01, -3.6248e-01, -1.1962e-01, -3.4462e-01, -5.5704e-01,\n",
       "        2.5797e-01,  3.3356e-01,  3.3194e-01, -3.1298e-01, -7.5547e-01,\n",
       "       -7.5290e-01, -9.3072e-02, -1.1173e-01, -5.7251e-01,  1.6639e-01,\n",
       "        6.3579e-01,  2.4006e-01, -2.9211e-01,  9.0182e-01,  1.2425e-01,\n",
       "       -5.7751e-01,  4.7986e-02, -4.2748e-01,  2.4446e-01,  4.7232e-02,\n",
       "        3.5694e-01,  4.4241e-01, -2.3055e-01,  6.6037e-01, -7.3983e-03,\n",
       "       -3.7857e-01,  2.2759e-01, -3.7138e-01,  3.1055e-01, -7.2105e-02,\n",
       "       -2.4490e-01, -3.9761e-02,  5.3650e-01, -4.1478e-01,  1.6563e-01,\n",
       "        3.3707e-01,  1.0920e-01,  3.7219e-01, -5.5727e-01, -7.8060e-01,\n",
       "        1.4251e-01, -3.5828e-01,  4.1638e-01,  2.1446e-01,  1.8410e-01,\n",
       "       -4.7704e-01, -2.2005e-02, -2.3634e-01, -2.2840e-01,  3.4722e-01,\n",
       "        2.3667e-01,  7.4249e-02, -8.8416e-02,  2.8618e-01, -4.6942e-01,\n",
       "       -4.3914e-01, -2.6474e-01, -3.0690e-01, -1.5260e-01, -8.4870e-02,\n",
       "        2.8410e-01, -1.8481e-01, -2.2122e-01, -1.1169e-01, -2.5241e-02,\n",
       "        4.5968e-02,  3.5343e-02,  2.2467e-01,  5.1556e-01, -6.5137e-04,\n",
       "        9.9559e-02, -1.4215e-01,  2.0136e-01,  2.8334e-01, -2.8772e-01,\n",
       "        3.7766e-02, -3.7608e-01, -1.1681e-01, -6.7020e-01, -4.6265e-02,\n",
       "        3.8784e-01, -3.2295e-02, -5.4291e-02, -4.5384e-01,  1.9552e-01,\n",
       "       -2.9470e-01,  8.5009e-01,  1.0345e-01,  9.7010e-02,  1.1339e-01,\n",
       "        3.9502e-01,  5.9043e-02,  2.1978e-01,  1.8845e-01, -1.5891e-01,\n",
       "       -1.0301e-01,  3.3164e-01,  6.1477e-02, -2.9848e-01,  4.4510e-01,\n",
       "        4.7329e-01,  2.6312e-01, -1.8495e-01,  1.4652e-01, -3.1510e-02,\n",
       "        2.2908e-02, -2.5929e-01, -3.0862e-01,  1.7545e-03, -1.8962e-01,\n",
       "        5.4789e-01,  3.1194e-01,  2.4693e-01,  2.9929e-01, -7.4861e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nlp('dog')\n",
    "tokens.vector\n",
    "##for en_core_web_md: this is how dog looks like for EVERYONE (us, google devs that made word2vec), \n",
    "##it's how dog is represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Most Similar Words (Using Our Old Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# inspect the default settings for CountVectorizer\n",
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = open(\"poor_amazon_toy_reviews.txt\").readlines()\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), \n",
    "                             stop_words=\"english\", \n",
    "                             max_features=500,token_pattern='(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b')\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "data = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# create similiarity matrix\n",
    "similarity_matrix = pd.DataFrame(cosine_similarity(data.T.values), \n",
    "             columns=vectorizer.get_feature_names(),\n",
    "                                 index=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack matrix into table\n",
    "similarity_table = similarity_matrix.rename_axis(None).rename_axis(None, axis=1).stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "similarity_table.columns = [\"word1\", \"word2\", \"similarity\"]\n",
    "similarity_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_table = similarity_table[similarity_table[\"similarity\"] < 0.99]\n",
    "similarity_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_table.sort_values(by=\"similarity\", ascending=False).drop_duplicates(\n",
    "    subset=\"similarity\", keep=\"first\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_500_words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Similar Words Using Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load into spacy your top 500 words\n",
    "\n",
    "tokens = nlp(f'{\" \".join(top_500_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# create a list of similarity tuples\n",
    "\n",
    "similarity_tuples = []\n",
    "\n",
    "for token1, token2 in product(tokens, repeat=2):\n",
    "    similarity_tuples.append((token1, token2, token1.similarity(token2)))\n",
    "\n",
    "similarities = pd.DataFrame(similarity_tuples, columns=[\"word1\",\"word2\", \"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similar words\n",
    "similarities[similarities[\"score\"] < 1].sort_values(\n",
    "    by=\"score\", ascending=False).drop_duplicates(\n",
    "    subset=\"score\", keep=\"first\").head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
